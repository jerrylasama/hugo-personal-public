[{"content":" Requirements  TensorFlow 2 Numpy Pillow Matplotlib / Seaborn / Your preferred data visualization library  You can easily install those libraries by using pip or conda. For example:\npip install tensorflow Preparing The Dataset Suppose you have a directory categorized per folder like this:\ndataset/\n├─ train/ │ ├─ dog/ │ │ ├─ dog001.jpg │ │ ├─ dog002.jpg │ ├─ cat/ │ │ ├─ cat001.jpg │ │ ├─ cat002.jpg ├─ valid/ │ ├─ dog/ │ │ ├─ dog001.jpg │ ├─ cat/ │ │ ├─ cat001.jpg\nYou can load the images using ImageDataGenerator it would automatically generate the class based on the folder.\nImport the libraries that we will use later on\nimport tensorflow as tf import numpy as np import matplotlib.pyplot as plt # Training Configurations batch_size = 64 # Depends on your RAM/VRAM capacity target_size = (256, 256) input_shape = (256, 256, 3) epochs = 200 seed = 42 # Directory containing the dataset train_dir = \u0026#34;dataset/train\u0026#34; valid_dir = \u0026#34;dataset/valid\u0026#34; # Create ImageDataGenerator img_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1. / 255) train = img_data_generator.flow_from_directory(directory=train_dir, batch_size=batch_size, shuffle=True, seed=seed, target_size=target_size, class_mode=\u0026#39;categorical\u0026#39;) valid = img_data_generator.flow_from_directory(directory=valid_dir, batch_size=batch_size, shuffle=True, seed=seed, target_size=target_size, class_mode=\u0026#39;categorical\u0026#39;) Building the model In this example, I will usekeras.applicationsMobileNetV2 you can use any other model you prefer\nmodel = tf.keras.applications.MobileNetV2(include_top=False, input_shape=input_shape) model.trainable = False # Defining input and output layers input_layer = tf.keras.Input(shape=input_shape) # Append MobileNetV2 to output layer model_layers = model(input_layer) model_layers = tf.keras.layers.Flatten()(model_layers) # flatten last layer output_layer = tf.keras.layers.Dense(38, activation=\u0026#39;softmax\u0026#39;)(model_layers) model = tf.keras.Model(input_layer, output_layer) model.summary() Now you can define any callbacks and other metrics you want to use. In this example i will use accuracy, precision, and recall so i could calculate the F1-Score later on.\ncallbacks = [ tf.keras.callbacks.ModelCheckpoint(filepath=\u0026#39;model.{epoch:02d}-{val_loss:.2f}.h5\u0026#39;) ] model.compile(optimizer=\u0026#39;Adam\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;,tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]) hist = model.fit(train, steps_per_epoch=len(train)/epochs, epochs=epochs, validation_data=valid, validation_steps=len(valid), callbacks=callbacks) F1-Score is defined as:\n$$ F1-Score = \\frac{2\\times precision \\times recall}{ precision + recall} $$\nYou can use hist object later to calculate F1-Score\nPlotting the result You can utilize hist to plot the model performance by using the metric as the key. For example:\n# Show all keys print(hist.history.keys()) # Plot accuracy plt.plot(hist.history[\u0026#39;accuracy\u0026#39;]) plt.plot(hist.history[\u0026#39;val_accuracy\u0026#39;]) plt.title(\u0026#39;model accuracy\u0026#39;) plt.ylabel(\u0026#39;accuracy\u0026#39;) plt.xlabel(\u0026#39;epoch\u0026#39;) plt.legend([\u0026#39;train\u0026#39;, \u0026#39;test\u0026#39;], loc=\u0026#39;upper left\u0026#39;) plt.show() And the result would be:\n  and you can save the model using model.save or you don\u0026rsquo;t have to if you used ModelCheckpoint callback early on.\n","date":"2021-04-07T00:00:00Z","permalink":"http://jerrylasama.xyz/p/introduction-to-image-classification-using-keras.applications/","title":"Introduction to Image Classification Using keras.applications"}]